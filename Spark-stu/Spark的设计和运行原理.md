# Spark的设计和运行原理

Spark是由美国加州伯克利的AMP实验室2009年开发的基于内存计算的大数据并行计算框架，可以用于构建大型、低延迟的数据分析应用。

## Spark的几个特点:
运行速度快（DAG，内存计算）、容易使用（支持Scala，java，python,R等）、通用性、运行模式多样

## Scala
Scala具备强大的并发性，支持函数式编程，可以更好的支持分布式系统。提供REPL（交互式解释器，能够提高程序开发效率）

## hadoop的缺点
- 表达能力有限——因为MapReduce，虽然降低程序开发复杂性，但是也降低了表达能力，有些问题无法转为MapReduce计算模型
- 磁盘IO开销大
- 延迟高（前一个任务结束之前，其他任务无法开始，难以胜任复杂、多阶段的计算任务）
## Spark相对Hadoop的优点
- Spark的计算模式也属于MapReduce，但是不局限于Map和Reduce操作，提供了多种数据集操作类型，更加灵活
- 提供内存计算，中间结果放在内存中，对于迭代运算效率更高
- 给予DAG的任务调度执行机制，优于Hadoop
  
## 两者的比较
- 数据存储结构：HDFS的Split对比 RDD 
- 编程范式：MapReduce 对比 Transformatin+Action
- 中间结果：磁盘IO，序列化、反序列化 对比 内存处理
- Task运行方式：以进程方式维护 对比 以线程方式维护

## Spark生态系统
1. 复杂的批量数据处理：时间跨度在数十分钟到数小时
2. 基于历史数据的交互式查询：时间跨度数十秒到数分钟
3. 基于实时数据流的数据处理：时间跨度数百毫秒到数秒

为了完成以上三种场景，可能需要同时部署下列：
1. hadoop mapreduce
2. Hive或者cloudera impala（基于历史数据的交互式查询，性能更强）
3. 给予实时数据流的数据处理
这三类功能一般部署在独立集群上，各自几百台服务器。但是这样就带来问题：   
1. 数据无法做到无缝共享
2. 使用成本高，需要不同的开发和维护团队
3. 难以对同一个集群中的各个系统进行统一的资源协调和分配
   
Spark遵循”一个软件栈满足不同应用场景的理念“，逐渐形成了一整套完整的生态系统。足以应对上述同时支持批处理、交互式查询和流数据处理。基于Spark可以实现BDAS架构

## Spark中的基本概念
- RDD：弹性分布式数据集，一方面是弹性的，也就是大小可变，一方面是分布式的，可以放在多台机器内存上
- DAG：邮箱无换图，反应RDD之间的依赖关系
- Executor：运行在工作节点的一个进程，负责运行Task
- Application:用户编写的Spark应用程序
- Task：运行在Exector上的工作单元
- Job：一个Job包含多个RDD以及作用于相应RDD上的各种操作
- Stage：是JOB的基本调度单位，一个JOB被分为多组Task，每一组成为一个Stage


## RDD的设计理念
在很多实际应用中，可能会多次使用中间结果，传统Mapreduce会将他们存入HDFS，磁盘IO耗费很大。而Spark引入RDD能将具体应用逻辑转换为一系列”转换“操作，实现了管道化，中间结果直接作为下一个RDD的输入，这样直接避免了中间结果的存储。

## RDD的概念
一个RDD就是一个`分布式对象集合`，本质是上一个只读的分区记录集合。每个RDD可分为多个`分区`，每个分区就是一个数据集片段，不同分区可以被保存到集群中不同节点上（`分布式`），这就实现了并行计算（`多个机器上并行计算`）

RDD提供了一种高度受限的共享内存模型，只能读，不能直接修改，只能给予稳定的物理存储中的数据集来创建，或者从其他RDD上转换（转换操作数量远大于mapreduce，包括map,join等）

RDD的操作分为两大类`转换(transformation)`和`动作（Action）`，转换操作能够让RDD互相转化，但是操作并不实际执行，只有到action操作时，计算才实际执行。   

注意：**`RDD里的转换接口是针对RDD整体的，不能说针对某个数据项去转换`**

## RDD的典型执行过程
1. RDD读入外部数据源进行创建（来自HDFS或者其他磁盘文件系统）
2. RDD经过一系列转换操作，每次都会生成新的RDD给下一阶段的”转换“使用
3. 最后一个RDD经过”行动“操作进行实际处理，输出到外部

注意：RDD采用了`惰性调用`，也就是真正的计算发生在”行动“操作时，而之前的所有”转换“操作，Spark只是记录下转换的轨迹，而不会真的计算。

从RDD创建到转换，到最后执行的整个图就叫DAG图。这一系列处理称为”`血缘关系`“，也就是DAG拓扑排序的结果。经过血缘关系的处理，这些RDD之间形成了管道化的执行序列，中间结果不需要保存可以直接传递给下一步。而这在MapReduce中是不能实现的。

## RDD为什么能够实现高效计算？
1. 容错性：天生具有容错性，我们现有的容错机制是数据复制（检查点）和记录日志的方式，针对大量数据时这样的方式很难执行。 RDD也采用日志方式，但是它记录的内容很粗粒度，因为它只记录转换操作，这些内容很少。一旦错误发生，不需要回滚整个系统，只需要重新计算丢失分区就行了。
2. 中间结果持久化到内存
3. 存放的数据可以使JAVA对象，避免了不必要的对象序列化和反序列化

## RDD窄依赖和宽依赖
1. 当父RDD的`一个分区`只能对应一个子RDD的`分区`时，称为窄依赖，这有两种情况（一对一和多对一）
2. 一个父RDD的一个分区对应于子RDD里的多个分区
宽依赖比窄依赖复杂得多，一般产生在Shuffle操作里。宽依赖中想要回复一个分区的代价比较高。   
`Spark通过分析各个rdd分区之间的依赖关系，来决定如何划分Stage`   
### 划分阶段的算法
1. 在DAG中进行反向解析，遇到宽依赖就断开
2. 遇到窄依赖，就把当前的RDD加入到目前Stage中
3. 将窄依赖尽量划分在同一个Stage中，可以实现流水线计算
`流水线操作就是指，假设有两个平行的转换路径，那么每个路径的执行不需要等待其他路径转换完成，而是可以像流水线一样直接去执行。`

### RDD的运行过程
1. 写代码，也就是创建RDD对象，系统会根据我们的代码去生成DAG图
2. SparkContext会负责计算DAG图中的依赖关系，找出宽窄依赖
3. DAGScheduler会负责把DAG图分解为多个阶段，然后每个阶段都包含了一组任务集
4. 每个Task会被TaskScheduler分发给各个WorkerNode上的Executor去执行（TaskScheduler是在集群资源管理器上的，可能是Yarn上的）

